{"samples": [" He is living with the Mulvilles."]}
{"samples": [" Ann is already in love with another man."]}
{"samples": [" On Atlas' mountain"]}
{"samples": [" To propose a plan of escape."]}
{"samples": [" Baron Henry didn't kill Otto because he was afraid of the Baron Conrad's reaction."]}
{"samples": [" at least six hours"]}
{"samples": [" Lisa"]}
{"samples": [" Janosz"]}
{"samples": [" American"]}
{"samples": [" the lying scribe"]}
{"samples": [" His 20th Century experience and understanding of military tactics and strategy."]}
{"samples": [" \"grayish-yellowish stuff,\" \"number on a large disk of metal strapped round the left arm,\" \"smelling rather strongly of carbolic,\" \"quite hairless\""]}
{"samples": [" fifty years"]}
{"samples": [" Virginie"]}
{"samples": [" Pierre Grassou"]}
{"samples": [" Vigo's painting comes to life and the slime spreads over the painting."]}
{"samples": [" Elder Childers argues that he is calm and sure of himself."]}
{"samples": [" His 20th Century experience and understanding of military tactics and strategy."]}
{"samples": [" A woman brushing her long hair before an oval-shaped mirror."]}
{"samples": [" Three"]}
{"samples": [" A family quarrel about money."]}
{"samples": [" 2419 A.D."]}
{"samples": [" To follow the harvest."]}
{"samples": [" A miserable slave"]}
{"samples": [" Lady Coxon is Ruth Anvoy's aunt."]}
{"samples": [" News reporter"]}
{"samples": [" He believes it would be wrong to betray the principles he has always upheld, including not doing evil or returning evil for evil."]}
{"samples": [" Drexl is killed by Clarence."]}
{"samples": [" She gave it up."]}
{"samples": [" twisted into an insane rictus of fear"]}
{"samples": [" Beerbohm is making fun of Soames's work."]}
{"samples": [" one week"]}
{"samples": [" Raval"]}
{"samples": [" She attended to the _shews_ of things, and her opinions were such as the generality approved of."]}
{"samples": [" Anderson's ability to work with chlorophage."]}
{"samples": [" He was worried about Ruth because he was afraid she might reveal their relationship to the authorities."]}
{"samples": [" Bill was shot by Benson."]}
{"samples": [" To investigate the \"Cornish Horror\" case."]}
{"samples": [" Vigo"]}
{"samples": [" Mary is initially educated with the expectation of a large fortune."]}
{"samples": [" Dana's apartment"]}
{"samples": [" Sadako"]}
{"samples": [" The Prison of Socrates."]}
{"samples": [" Shizuko Yamamura committed suicide."]}
{"samples": [" Seth Lazurus was accused of murder."]}
{"samples": [" He wore a soft black hat of clerical kind, but of Bohemian intention, and a gray waterproof cape which, perhaps because it was waterproof, failed to be romantic."]}
{"samples": [" Baron Henry of Trutz-Drachen"]}
{"samples": [" Mary is initially educated with the expectation of a large fortune."]}
{"samples": [" Baptist"]}
{"samples": [" Miss Vane"]}
{"samples": [" Dark ages, ignorance, superstition, cruelty, wickedness, gentleness, love, peace, justice, wisdom, and redemption."]}
{"samples": [" Tomoko dies."]}
{"samples": [" twisted into an insane rictus of fear"]}
{"samples": [" The Sinsings"]}
{"samples": [" Bill"]}
{"samples": [" They sing the Ghostbusters theme song."]}
{"samples": [" He draws the magnificent income from The Coxon Fund."]}
{"samples": [" Falder"]}
{"samples": [" Not specified in the context."]}
{"samples": [" A check"]}
{"samples": [" A sexless thing"]}
{"samples": [" In the closet."]}
{"samples": [" Sarah"]}
{"samples": [" Eatonville"]}
{"samples": [" Dr. Richards"]}
{"samples": [" JEZZIE"]}
{"samples": [" ship's doctor"]}
{"samples": [" Buy a good house."]}
{"samples": [" Her mother"]}
{"samples": [" one week"]}
{"samples": [" Virginie Vervelle"]}
{"samples": [" She copies the tape and shows it to someone else."]}
{"samples": [" A painter"]}
{"samples": [" They agree to obey the laws and commands of the city."]}
{"samples": [" He jumped."]}
{"samples": [" copying the tape and showing it to someone else"]}
{"samples": [" Brenda Treginnis"]}
{"samples": [" They slept in the same room."]}
{"samples": [" ramble about the garden, admire the flowers, play with the dogs"]}
{"samples": [" security guard"]}
{"samples": [" Radioactive gases"]}
{"samples": [" Izu Pacific Land"]}
{"samples": [" Dick's number in Hollywood."]}
{"samples": [" 100 years"]}
{"samples": [" Holmes upset the watering-pot."]}
{"samples": [" An enemy"]}
{"samples": [" HECTOR FROME"]}
{"samples": [" Louis"]}
{"samples": [" His failure to impress himself on his decade."]}
{"samples": [" Eliza"]}
{"samples": [" Bad Bloods"]}
{"samples": [" In front of Cliff's trailer home."]}
{"samples": [" Oscar is Dana's son."]}
{"samples": [" The laws in the world below will receive him as an enemy."]}
{"samples": [" Open the closet door."]}
{"samples": [" Doctor Nordenfeld"]}
{"samples": [" \"one of the most honest fellows on earth\""]}
{"samples": [" Artists laugh at his work."]}
{"samples": [" Lee Donowitz"]}
{"samples": [" He failed to report himself this last four weeks."]}
{"samples": [" Ruth"]}
{"samples": [" Detroit"]}
{"samples": [" \"My child, I have not always treated you with kindness--God forgive me! do you?\""]}
{"samples": [" \"Are you prepared?\""]}
{"samples": [" No one"]}
{"samples": [" Mary is taught to dance."]}
{"samples": [" A painter"]}
{"samples": [" To fulfill her mother's dying wish."]}
{"samples": [" Mortimer Tregennis"]}
{"samples": [" Jacob first meets Michael Newman in a hotel room."]}
{"samples": [" American"]}
{"samples": [" Bad Bloods"]}
{"samples": [" September 21st. Tuesday."]}
{"samples": [" Ruth Anvoy"]}
{"samples": [" They go to play for the white folks."]}
{"samples": [" The dark or middle ages."]}
{"samples": [" Ryuji is killed by Sadako."]}
{"samples": [" He had one or two places, but he didn't keep them."]}
{"samples": [" He is living with the Mulvilles."]}
{"samples": [" In the closet."]}
{"samples": [" Artists laugh at his work; his name is a term of contempt in the studios."]}
{"samples": [" A cursed videotape."]}
{"samples": [" Alabama was a stewardess."]}
{"samples": [" A demonic presence."]}
{"samples": [" \"your capacity for self-delusion\""]}
{"samples": [" The agreement to obey the laws and the government."]}
{"samples": [" \"one of the most honest fellows on earth\""]}
{"samples": [" Sister Taylor"]}
{"samples": [" Lock him up in the Mayor's barn until Monday."]}
{"samples": [" her brother"]}
{"samples": [" \"Otto of the Silver Hand\""]}
{"samples": [" her brother"]}
{"samples": [" Wyoming Valley, Pennsylvania"]}
{"samples": [" Soames was a figment of my brain."]}
{"samples": [" A family quarrel about money."]}
{"samples": [" Altaira"]}
{"samples": [" Pierre Grassou"]}
{"samples": [" He discovered that she was not in bed."]}
{"samples": [" \"Shoumon bakkari... boukon ga kuru zo.\""]}
{"samples": [" A house in Vendome, known as the property of the late Madame de Merret."]}
{"samples": [" They decided not to give the money to Saltram."]}
{"samples": [" Miss Violet Ray"]}
{"samples": [" Bill"]}
{"samples": [" Tomoko Ouishi and Iwata"]}
{"samples": [" First World War"]}
{"samples": [" He discovers that his own paintings are in Vervelle's collection."]}
{"samples": [" Vietnam field hospital"]}
{"samples": [" Citizens and the law are compared to a father and a child."]}
{"samples": [" The coffin"]}
{"samples": [" 2419 A.D."]}
{"samples": [" Baron Conrad is killed in a battle with his enemies."]}
{"samples": [" Lee grabs the coffee pot off the table and flings hot coffee into Elliot's face."]}
{"samples": [" Eatonville"]}
{"samples": [" Madame de Merret"]}
{"samples": [" Gravener was urging Anvoy to marry him."]}
{"samples": [" By visiting the reading-room of the British Museum in 1997."]}
{"samples": [" Apis"]}
{"samples": [" Two"]}
{"samples": [" Alabama Worley"]}
{"samples": [" Bill"]}
{"samples": [" Elie Magus"]}
{"samples": [" \"Higher and Higher\""]}
{"samples": [" Artists laugh at his work; that his name is a term of contempt in the studios; and that the feuilletons take no notice of his pictures."]}
{"samples": [" Charles, her father's friend's son."]}
{"samples": [" A house in Vendome, known as the property of the late Madame de Merret."]}
{"samples": [" \"Higher and Higher\""]}
{"samples": [" At about a hundred paces from Vendome, on the banks of the Loir."]}
{"samples": [" Over Daisy Taylor"]}
{"samples": [" Bruce Joel Rubin"]}
{"samples": [" Baron Conrad's wound"]}
{"samples": [" Strange panacea in a crystal bowl."]}
{"samples": [" Ville d'Avray"]}
{"samples": [" To rescue his kinsman, William of Roderburg, who was held captive by Baron Conrad."]}
{"samples": [" Bill was shot by Benson."]}
{"samples": [" Sister Thomas"]}
{"samples": [" People were going to stare at him and follow him around and seem afraid of him."]}
{"samples": [" Abby"]}
{"samples": [" Governor of the state"]}
{"samples": [" \"old way\" spelling"]}
{"samples": [" It causes hallucinations and visions of demons."]}
{"samples": [" The mother, her niece, and nephew."]}
{"samples": [" In the bathroom."]}
{"samples": [" Jacob's unit was involved in a massacre."]}
{"samples": [" Leave a crack at the bottom."]}
{"samples": [" On Atlas' mountain"]}
{"samples": [" St. Michaelsburg"]}
{"samples": [" An enemy"]}
{"samples": [" French letters"]}
{"samples": [" The naked beauty of the soul"]}
{"samples": [" In a dark Chicago mill."]}
{"samples": [" Miranda Hope"]}
{"samples": [" Nine pounds"]}
{"samples": [" Holmes upset the watering-pot."]}
{"samples": [" Ryuji is killed by Sadako."]}
{"samples": [" Eatonville"]}
{"samples": [" Mortimer Tregennis"]}
{"samples": [" charred ashes"]}
{"samples": [" American Radioactive Gas Corporation"]}
{"samples": [" Raval"]}
{"samples": [" September 21st. Tuesday."]}
{"samples": [" An expert manually inspected the text field within the tweets to label them as containing fake news, or not containing them."]}
{"samples": [" Ghost-VLAD is an extension of the NetVLAD approach, which was proposed for face recognition by Y. Zhong. It adds Ghost clusters along with the NetVLAD clusters to map any noisy or irrelevant content into ghost clusters and are not included during the feature aggregation stage."]}
{"samples": [" 68.8% to 71.8%"]}
{"samples": [" Context tweets"]}
{"samples": [" FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."]}
{"samples": [" Yes"]}
{"samples": [" TrueSkill"]}
{"samples": [" CNN/DailyMail, NYT, XSum"]}
{"samples": [" GM_KL performs better than other approaches on the benchmark word similarity and entailment datasets."]}
{"samples": [" They start with the best performing model and add the best performing model that hasn't been tried yet, keeping it in the ensemble if it improves validation performance and discarding it otherwise."]}
{"samples": [" Friends is from the scripts of the Friends TV sitcom and EmotionPush is from Facebook messenger chats."]}
{"samples": [" English"]}
{"samples": [" IMDb dataset"]}
{"samples": [" The proposed system outperforms strong baseline systems."]}
{"samples": [" Yes"]}
{"samples": [" Twitter posts and news articles related to finance."]}
{"samples": [" unanswerable"]}
{"samples": [" RNN-based NMT and Transformer-NMT"]}
{"samples": [" (1) a regularization term associated with neutral features; (2) the maximum entropy of class distribution regularization term; and (3) the KL divergence between reference and predicted class distribution."]}
{"samples": [" 1) SVM with unigram, bigram, and trigram features, 2) SVM with average word embedding, 3) SVM with average transformed word embeddings, 4) CNN and Recurrent Convolutional Neural Networks, 5) SVM and deep learning models with comment information, 6) UTCNN without user information, 7) UTCNN without the LDA model, 8) UTCNN without comments."]}
{"samples": [" several points"]}
{"samples": [" By allowing attention mappings to dynamically adapt their curvature and sparsity, and by enabling different heads to learn different sparsity behaviors."]}
{"samples": [" The baseline was a context-agnostic MT model."]}
{"samples": [" XNLI test accuracy, Labeled Attachment Scores (LAS)"]}
{"samples": [" ASR, MT and ST respectively"]}
{"samples": [" Stylistic patterns and patterns related to situational disparity."]}
{"samples": [" LSTM"]}
{"samples": [" Yes"]}
{"samples": [" Jasper architecture"]}
{"samples": [" 22,880 users"]}
{"samples": [" BPE perplexity, BLEU-1/4, ROUGE-L, Distinct-1/2, User matching accuracy (UMA), Mean Reciprocal Rank (MRR), recipe-level coherence scores, step entailment score."]}
{"samples": [" \"completed symptoms\", \"to-do symptoms\", \"completed attributes\", \"to-do attributes\""]}
{"samples": [" 5k abstracts"]}
{"samples": [" Four machine translation tasks."]}
{"samples": [" ELMo embeddings show the largest improvement over fastText embeddings."]}
{"samples": [" unanswerable"]}
{"samples": [" yes"]}
{"samples": [" The Nguni languages and the Sotho languages."]}
{"samples": [" 6-layers and 9-layers sMBR models"]}
{"samples": [" 29,794 articles"]}
{"samples": [" A group of 50 native people who were well-versed in both English and Tamil languages acted as annotators for the evaluation."]}
{"samples": [" Yes"]}
{"samples": [" Efficiency of a communication scheme is measured by the retention rate of tokens, and the accuracy is measured as the fraction of sentences generated by greedily decoding the model that exactly matches the target sentence."]}
{"samples": [" Precision, Recall and F-measure"]}
{"samples": [" The source domain is the existing domain with sufficient labeled data, and the target domain is the new domain with very few or no labeled data."]}
{"samples": [" LSTM"]}
{"samples": [" RNN, CNN, QRNN, Transformer, Highway network, Encoder Decoder architecture, Linear/Bi-linear Attention, Full Attention, Bidirectional attention flow, Dropout, Layer Norm, Batch Norm."]}
{"samples": [" The multilingual pronunciation corpus collected by deri2016grapheme and the Carnegie Mellon Pronouncing Dictionary."]}
{"samples": [" unanswerable"]}
{"samples": [" English, Spanish, Finnish"]}
{"samples": [" Named Entity Recognition, POS tagging, text classification, language modeling"]}
{"samples": [" Yes"]}
{"samples": [" yes"]}
{"samples": [" They use the Meaning Extraction Method (MEM) to measure the usage of words related to people's core values."]}
{"samples": [" Claims, premises, backing, rebuttal, and refutation."]}
{"samples": [" n-grams"]}
{"samples": [" 1,873 Twitter conversation threads, roughly 14k tweets"]}
{"samples": [" The 12 languages covered are typologically diverse and include also under-resourced ones, such as Welsh and Kiswahili."]}
{"samples": [" Wikipedia conversations dataset and Reddit CMV dataset."]}
{"samples": [" unanswerable"]}
{"samples": [" Sanity checks, BLEU scores, perplexity, character ratio, and similarity scores."]}
{"samples": [" They combine the information from these sources using a feed-forward neural model."]}
{"samples": [" 2.11 BLEU, 1.7 FKGL and 1.07 SARI."]}
{"samples": [" 700 examples"]}
{"samples": [" A tweet went viral if it was retweeted more than 1000 times."]}
{"samples": [" LSTM-CRF"]}
{"samples": [" crowdsourcing"]}
{"samples": [" Logistic Regression and neural networks"]}
{"samples": [" The benchmark dataset is a dataset built by Lee et al. using a social honeypot to attract social spammers' retweet. Its quality is not explicitly mentioned in the context."]}
{"samples": [" LSTM decoder"]}
{"samples": [" unanswerable"]}
{"samples": [" The best performing model is the ensemble+ of (II and IV) from each of the folds 1-3, i.e., $|{\\mathcal {M}}|=6$ models, ranked at 3rd position."]}
{"samples": [" (b3)"]}
{"samples": [" '0.7033'"]}
{"samples": [" Word embedding techniques such as word2vec"]}
{"samples": [" They use a bilingual dictionary for transfer information from the assisting to the source language."]}
{"samples": [" Yes"]}
{"samples": [" Seven experts with legal training."]}
{"samples": [" CNN-RNN based image-to-poem net and seq2seq model with parallel text corpus for painting embedding; sequence-to-sequence model with attention for language style transfer."]}
{"samples": [" ToBERT"]}
{"samples": [" yes"]}
{"samples": [" Personal attack, racism, and sexism"]}
{"samples": [" They propose extended middle context, a new context representation for CNNs for relation classification."]}
{"samples": [" 4"]}
{"samples": [" higher quality"]}
{"samples": [" 65% of the speakers are men, speaking more than 75% of the time."]}
{"samples": [" English-German dataset"]}
{"samples": [" previous state-of-the-art models"]}
{"samples": [" Logistic Regression (LR) and Multilayer Perceptron (MLP)"]}
{"samples": [" BIBREF17 and BIBREF18"]}
{"samples": [" SQuAD dataset"]}
{"samples": [" Various approaches have been proposed for modelling urban regions and identifying points-of-interest and itineraries."]}
{"samples": [" Yes"]}
{"samples": [" CSAT dataset, 20 newsgroups, Fisher Phase 1 corpus"]}
{"samples": [" IMDb movie review dataset"]}
{"samples": [" Yes"]}
{"samples": [" no"]}
{"samples": [" INLINEFORM0 and INLINEFORM1 exists."]}
{"samples": [" The full catalogue of features, their description, detailed annotation guideline as well as illustrating examples can be found in Appendix."]}
{"samples": [" WikiSmall has 89,042 sentence pairs and WikiLarge has 296,402 sentence pairs."]}
{"samples": [" Vanilla ST baseline, Pre-training baselines, Multi-task baselines, Many-to-many+pre-training, Triangle+pre-train."]}
{"samples": [" English"]}
{"samples": [" SVM, BiLSTM, CNN"]}
{"samples": [" unanswerable"]}
{"samples": [" GloVe, Edinburgh embeddings, Emoji embeddings"]}
{"samples": [" They generated high-quality and specific recipes that align with historical user preferences."]}
{"samples": [" A combination of rewards for irony accuracy, sentiment preservation and content preservation."]}
{"samples": [" The generated English poem may not work well with Shakespeare style transfer as shown in Figure FIGREF12 for \"Starry Night\" with a low average content score."]}
{"samples": [" Affective Text dataset, Fairy Tales dataset, and the ISEAR dataset."]}
{"samples": [" The distribution results are not provided in the context."]}
{"samples": [" From the Stanford Sentiment Analysis Dataset."]}
{"samples": [" Persian and English"]}
{"samples": [" The context of the corresponding text."]}
{"samples": [" Random Forests (RF)"]}
{"samples": [" unanswerable"]}
{"samples": [" 110-hour German-English ST corpus"]}
{"samples": [" The high-quality datasets the challenge organizers released."]}
{"samples": [" BERT$_\\mathrm {BASE}$"]}
{"samples": [" Yes"]}
{"samples": [" unanswerable"]}
{"samples": [" Competitive results"]}
{"samples": [" INLINEFORM0 tagging scheme"]}
{"samples": [" no"]}
{"samples": [" \"make the model more robust and practical\""]}
{"samples": [" InferSent, Universal Sentence Encoder"]}
{"samples": [" +0.29 and +0.97"]}
{"samples": [" Task 1: Quora Duplicate Question Pair Detection and Task 2: Ranking questions in Bing's People Also Ask"]}
{"samples": [" syntactic tree-based models, other neural models"]}
{"samples": [" Relation detection"]}
{"samples": [" A name-based Nearest-Neighbor model (NN) and a simple Encoder-Decoder baseline with ingredient attention (Enc-Dec)."]}
{"samples": [" Tagging descriptions with part-of-speech information, leveraging the structure of Flickr30K Entities, and creating a coreference graph."]}
{"samples": [" French"]}
{"samples": [" They experimented with the architecture without INLINEFORM2."]}
{"samples": [" no"]}
{"samples": [" Sumy package"]}
{"samples": [" BIBREF0"]}
{"samples": [" No"]}
{"samples": [" DTA corpus"]}
{"samples": [" Kannada, Hindi, Telugu, Malayalam, Bengali, and English."]}
{"samples": [" Competitive performance"]}
{"samples": [" significant improvement"]}
{"samples": [" \"unanswerable\""]}
{"samples": [" The ability of the model to detect some biases in the process of collecting or annotating datasets."]}
{"samples": [" Yes"]}
{"samples": [" 14 million words"]}
{"samples": [" +0.58 for MRPC and +0.73 for QQP."]}
{"samples": [" eye-tracking, self-paced reading, and ERP components"]}
{"samples": [" 7 phonemic/syllabic and 4 words"]}
{"samples": [" Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN, Pointer-Gen+ARL-SEN."]}
{"samples": [" Traditional machine learning classifiers and neural network based models."]}
{"samples": [" A bi-directional language model and a uni-directional model."]}
{"samples": [" Associated with each training example in proportion to $(1-p)$, and this weight dynamically changes as training proceeds."]}
{"samples": [" Agents utilizing knowledge-graphs in addition to either enhanced exploration method far outperform the baseline A2C and KG-A2C."]}
{"samples": [" Individual Bayesian models for each language."]}
{"samples": [" Foreign words, in this case Spanish words, are also labelled as such."]}
{"samples": [" A semicharacter architecture is a type of neural network architecture that processes a sentence of words with misspelled characters, predicting the correct words at each step."]}
{"samples": [" 16 languages"]}
{"samples": [" NCEL outperforms the state-of-the-art collective methods across five different datasets."]}
{"samples": [" Yes"]}
{"samples": [" The baseline used was the error detection system by Rei2016, trained using the same FCE dataset."]}
{"samples": [" 2010 i2b2/VA"]}
{"samples": [" It allows the decoder to generate context vectors and refine the summary word based on the source document and other words."]}
{"samples": [" PPDB"]}
{"samples": [" TF-IDF features"]}
{"samples": [" Each tweet is annotated as no evidence of depression or evidence of depression with one or more depressive symptoms."]}
{"samples": [" eight publicly available NER tasks"]}
{"samples": [" The machine translation platform Apertium was used for the translation of the datasets."]}
{"samples": [" multinomial Naive Bayes classifier"]}
{"samples": [" A very simple logistic regression classifier with default parameters, where the input instances are represented with a single feature: the length of the sentence."]}
{"samples": [" CRF"]}
{"samples": [" The procedure proposed in BIBREF2 is used to label different outlets."]}
{"samples": [" ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era."]}
{"samples": [" English"]}
{"samples": [" unanswerable"]}
{"samples": [" three convolutional layers"]}
{"samples": [" European network of nature protected sites Natura 2000 dataset"]}
{"samples": [" NUBes-PHI and MEDDOCAN"]}
{"samples": [" Unigrams and Pragmatic features"]}
{"samples": [" Coverage, Avg. MCC, avg. +ve F1 score"]}
{"samples": [" Yes"]}
{"samples": [" Galatasaray and Fenerbah\u00e7e"]}
{"samples": [" Additional experiments on the transformation from ironic sentences to non-ironic sentences."]}
{"samples": [" Gaussian-masked directional multi-head attention is a variant of self-attention that captures representation of different directions to improve the ability of capturing the localness information and position information for the importance of adjacent characters."]}
{"samples": [" Facebook"]}
{"samples": [" 100 baseline features"]}
{"samples": [" number of clusters, seed initialization"]}
{"samples": [" Second (EI-Reg), second (EI-Oc), fourth (V-Reg) and fifth (V-Oc)"]}
{"samples": [" The corpus consists of 53 documents, which contain an average number of 156.1 sentences per document, each with 19.55 tokens on average."]}
{"samples": [" Yes"]}
{"samples": [" Text categorization and sentiment classification."]}
{"samples": [" Li and Roth BIBREF6 model"]}
{"samples": [" The training sets of these versions of ELMo are larger."]}
{"samples": [" 6946 sentences"]}
{"samples": [" MLP, Eusboost, MWMOTE"]}
{"samples": [" Yes"]}
{"samples": [" Yes"]}
{"samples": [" '0.6103'"]}
{"samples": [" The Wall Street Journal (WSJ) portion of the Penn Treebank."]}
{"samples": [" \"Related Work\""]}
{"samples": [" SimpleQuestions and WebQSP"]}
