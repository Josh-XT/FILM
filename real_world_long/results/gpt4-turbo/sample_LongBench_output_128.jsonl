{"sample": "He lives with the Mulvilles."}
{"sample": "Ann's heart is preoccupied with another."}
{"sample": "Atlas' mountain"}
{"sample": "To persuade Socrates to escape from prison."}
{"sample": null}
{"sample": "at least six hours"}
{"sample": "Lisa"}
{"sample": "Janosz Poha"}
{"sample": "American"}
{"sample": "the lying scribe"}
{"sample": "His knowledge of 20th-century military tactics and strategy."}
{"sample": "Uniformed crowd, phonetic spelling, people looking very well cared for, hairless or shorn individuals, and a sense of fear towards Soames."}
{"sample": "fifty years"}
{"sample": "Their daughter Virginie."}
{"sample": "Pierre Grassou"}
{"sample": "It starts to vibrate as if shaken by an unseen hand."}
{"sample": "Elder Childers argues that the town needs improvements, such as a jail, and criticizes Mayor Joe Clark for not making these changes."}
{"sample": "His knowledge of 20th-century military tactics and strategy."}
{"sample": "Her face is distorted."}
{"sample": "Three"}
{"sample": "a family quarrel about money"}
{"sample": "2419 A.D."}
{"sample": "To follow the harvest."}
{"sample": "betraying one's parents"}
{"sample": "Aunt"}
{"sample": "Reporter"}
{"sample": "Obedience to the laws and principles of justice."}
{"sample": "Shotgun blast"}
{"sample": "Destroyed it without reading it."}
{"sample": "Their faces were twisted into an insane rictus of fear, mouth open, eyes wide and glassy."}
{"sample": "Soames believed Beerbohm would make him seem imaginary in his writing."}
{"sample": "One week"}
{"sample": "Mia and Jof"}
{"sample": "Reading novels."}
{"sample": "There is no mention of a character named Anderson in the provided context."}
{"sample": "He loved her and she was in distress."}
{"sample": "Shot by Benson"}
{"sample": "Holmes's health needed a rest."}
{"sample": "Vigo the Carpathian"}
{"sample": "Mary is initially educated by an old house-keeper who tells her stories, reads to her, and teaches her to read."}
{"sample": "East 77th Street"}
{"sample": "Sadako Yamamura"}
{"sample": "The Prison of Socrates"}
{"sample": "Shizuko Yamamura committed suicide."}
{"sample": "There is no mention of Bennett Landsmann or Seth Lazurus in the provided story."}
{"sample": "Wearing a soft black hat of clerical kind and a gray waterproof cape."}
{"sample": "Baron Henry of Trutz-Drachen"}
{"sample": "Superficial accomplishments without any taste for them."}
{"sample": "Baptist"}
{"sample": "Lady Augusta Fleming"}
{"sample": "Good and evil, innocence and cruelty, the brutality of the Middle Ages, the power of love and gentleness."}
{"sample": "Tomoko dies in her closet, with a look of horror on her face."}
{"sample": "Their faces were twisted into an insane rictus of fear, mouth open, eyes wide and glassy."}
{"sample": "The Sinsings"}
{"sample": "Abby and Ursula"}
{"sample": "Sing the Ghostbusters theme song."}
{"sample": "Philosopher and lecturer"}
{"sample": "William Falder"}
{"sample": "There is no mention of a character named Laura or a medical school in the provided context."}
{"sample": "A check."}
{"sample": "A sexless creature with wings."}
{"sample": "In the closet."}
{"sample": null}
{"sample": "Eatonville, Florida"}
{"sample": "Dr. Richards and Mr. Mortimer Tregennis"}
{"sample": null}
{"sample": "There is no mention of a character named Landsmann in the provided story context."}
{"sample": "Buy a good house."}
{"sample": "Mrs. Abraham C. Mope"}
{"sample": "One week"}
{"sample": null}
{"sample": "She copies the tape and shows it to someone else."}
{"sample": "a monk"}
{"sample": "Obey the laws of the state."}
{"sample": "He jumped."}
{"sample": "Copying the tape and showing it to someone else."}
{"sample": "Brenda Tregennis"}
{"sample": "Madame de Merret fell ill and Monsieur de Merret did not leave her room until she recovered."}
{"sample": "Rambling about the garden and playing with the dogs."}
{"sample": "ex-cop, at present a security guard"}
{"sample": null}
{"sample": "Izu Pacific Land"}
{"sample": "A suitcase full of cocaine"}
{"sample": "A hundred years"}
{"sample": "Holmes upset the watering-pot."}
{"sample": "An enemy of the laws and his country."}
{"sample": "Hector Frome"}
{"sample": "Dana Barrett"}
{"sample": "His lack of recognition and failure as a writer."}
{"sample": "Eliza"}
{"sample": "Bad Bloods"}
{"sample": "INT. BAR - NIGHT"}
{"sample": "Oscar is Dana's baby."}
{"sample": "He believes he will be judged as unjust and wronging himself, his friends, his country, and the laws."}
{"sample": "Opened the closet door."}
{"sample": "No one."}
{"sample": "mediocre"}
{"sample": "Artists laugh at his work."}
{"sample": "Blue Lou Boyle"}
{"sample": "He failed to report himself."}
{"sample": "Ruth Honeywill"}
{"sample": "There is no mention of Alabama having a son in the provided script."}
{"sample": "Eliza requests Mary to forgive her."}
{"sample": "Have you come for me?"}
{"sample": "There is no mention of Lazarus or a murder trial in the provided context."}
{"sample": "The duties of her station."}
{"sample": "a monk"}
{"sample": "Her father's will and her mother's desire."}
{"sample": "Dr. Leon Sterndale"}
{"sample": null}
{"sample": "American"}
{"sample": "The Han airship."}
{"sample": "When she finds Ryuji's dead body."}
{"sample": "Ruth Anvoy"}
{"sample": "Jim is arrested and taken to the barn; Dave is knocked out and tended to by the villagers."}
{"sample": "The dark or middle ages in Germany"}
{"sample": "Reiko's husband, Ryuji, dies."}
{"sample": "He had one or two places but didn't keep them."}
{"sample": "He lives with the Mulvilles."}
{"sample": "In the closet."}
{"sample": "Artists laugh at his work."}
{"sample": null}
{"sample": null}
{"sample": null}
{"sample": null}
{"sample": "The agreement with the laws and the state of Athens."}
{"sample": "mediocre artist"}
{"sample": "Elder Childers"}
{"sample": "Jim was not found guilty; the trial was interrupted and never concluded."}
{"sample": "Her son."}
{"sample": "Wisdom and peacefulness"}
{"sample": "Her dogs."}
{"sample": "Wyoming Valley"}
{"sample": "Imaginary character"}
{"sample": "a family quarrel about money"}
{"sample": "There is no mention of Dwyer or an in vitro clinic in the provided story."}
{"sample": "Pierre Grassou"}
{"sample": "Infidelity"}
{"sample": "Copy the tape and show it to someone else."}
{"sample": "An old isolated house in disrepair near Vendome."}
{"sample": "Their engagement ended."}
{"sample": "Miss Violet Ray"}
{"sample": "Bill"}
{"sample": "Tomoko and Yoichi"}
{"sample": null}
{"sample": "Grassou discovers that many of the paintings in Vervelle's art collection are actually his own works, sold to Elie Magus and passed off as masterpieces by famous artists."}
{"sample": null}
{"sample": "Children and parents."}
{"sample": "The coffin"}
{"sample": "2419 A.D."}
{"sample": "Otto is mutilated by Baron Henry of Trutz-Drachen."}
{"sample": "Lee throws hot coffee in Elliot's face."}
{"sample": "Eatonville"}
{"sample": "Madame de Merret"}
{"sample": "Marry him."}
{"sample": "By being projected into the reading-room of the British Museum a hundred years hence."}
{"sample": "Apis"}
{"sample": "Two people (Mrs. Porter and the vicar)."}
{"sample": "Alabama Worley"}
{"sample": "Bill kills Chuck with a spoke."}
{"sample": "Elie Magus"}
{"sample": "\"Auld Lang Syne\""}
{"sample": "Artists laugh at his work."}
{"sample": "Charles."}
{"sample": "An old isolated house in disrepair near Vendome."}
{"sample": "\"Auld Lang Syne\""}
{"sample": "At about a hundred paces from Vendome, on the banks of the Loir."}
{"sample": "Over Daisy Taylor's attention."}
{"sample": null}
{"sample": "Because she saw her husband, Baron Conrad, wounded and thought him dead."}
{"sample": "Strange dreams on the brain"}
{"sample": "Ville d'Avray"}
{"sample": "Revenge for the caravan attack."}
{"sample": "Shot by Benson"}
{"sample": "Elder Simms"}
{"sample": "He scared them and they avoided him."}
{"sample": "Abby"}
{"sample": "Governor of the state"}
{"sample": "Proper names were still spelled in the old way."}
{"sample": null}
{"sample": "Henry and his family."}
{"sample": "In his trailer home."}
{"sample": null}
{"sample": "Leave a crack at the bottom."}
{"sample": "Atlas' mountain"}
{"sample": "St. Michaelsburg"}
{"sample": "A subverter of the laws"}
{"sample": "Leon's romantic conquests"}
{"sample": "The naked beauty of the soul."}
{"sample": "Chicago mill"}
{"sample": "Dr. Rudolf Staub"}
{"sample": "Ninety pounds"}
{"sample": "Holmes upset the watering-pot."}
{"sample": "Reiko's husband, Ryuji, dies."}
{"sample": "Eatonville"}
{"sample": "Brenda Tregennis and Mortimer Tregennis"}
{"sample": "Charred ashes of the overnight fire"}
{"sample": "American Radioactive Gas Corporation"}
{"sample": "Mia and Jof"}
{"sample": "When she finds Ryuji's dead body."}
{"sample": "The ground truth for fake news was established by manual annotation carried out by a single person."}
{"sample": "The GhostVLAD approach is an extension of the NetVLAD pooling strategy that adds Ghost clusters to map noisy or irrelevant content and exclude them during the feature aggregation stage, improving the discriminative properties of the resulting features for tasks like language identification."}
{"sample": "68.8% to 71.8%"}
{"sample": "The use of context tweets as an additional feature."}
{"sample": "FoxNews, CNN, ESPN, New York Times, Time magazine, Huffington Post Weird News, The Guardian, Cartoon Network, Cooking Light, Home Cooking Adventure, Justin Bieber, Nickelodeon, Spongebob, Disney."}
{"sample": "Yes"}
{"sample": "Extrinsic evaluation in the task of summary evaluation."}
{"sample": "CNN/DailyMail, New York Times Annotated Corpus (NYT), and XSum."}
{"sample": "Unanswerable."}
{"sample": "The ensemble method works by starting with the best performing model according to validation performance, then iteratively adding the best performing model that had not been previously tried, keeping it if it improved validation performance and discarding it otherwise, until each model has been tried once, resulting in a greedy ensemble."}
{"sample": "Friends TV sitcom scripts and Facebook messenger chats."}
{"sample": "English"}
{"sample": "IMDb dataset of movie reviews"}
{"sample": "unanswerable"}
{"sample": "Yes"}
{"sample": "The datasets used are a set of thousand documents related to finance, consisting of 184,001 Twitter posts and 62,949 news articles."}
{"sample": "Energy sector."}
{"sample": "RNN-based NMT and Transformer-NMT"}
{"sample": "(1) a regularization term associated with neutral features; (2) the maximum entropy of class distribution regularization term; (3) the KL divergence between reference and predicted class distribution."}
{"sample": "1) SVM with unigram, bigram, and trigram features; 2) SVM with average word embedding; 3) SVM with average transformed word embeddings; 4) CNN; 5) Recurrent Convolutional Neural Networks (RCNN); 6) UTCNN without user information; 7) UTCNN without the LDA model; 8) UTCNN without comments."}
{"sample": "unanswerable"}
{"sample": "Our model improves interpretability by identifying both crisper examples of attention head behavior and novel behaviors thanks to the sparsity and adaptivity of our proposed model."}
{"sample": "The baseline model is a Transformer base model used for initial sentence-level translations without context-aware corrections."}
{"sample": "XNLI test accuracy and Labeled Attachment Scores (LAS) for dependency parsing."}
{"sample": "MT dataset $\\mathcal {M}$"}
{"sample": "Unanswerable."}
{"sample": "LSTM encoder"}
{"sample": "Yes"}
{"sample": "unanswerable"}
{"sample": "22,880 users"}
{"sample": "Perplexity, user-ranking, BLEU-1/4, ROUGE-L, Distinct-1/2, user matching accuracy (UMA), Mean Reciprocal Rank (MRR), recipe-level coherence, and step entailment score."}
{"sample": "No Answer"}
{"sample": "unanswerable"}
{"sample": "machine translation tasks"}
{"sample": "unanswerable"}
{"sample": "unanswerable"}
{"sample": "No"}
{"sample": "The Nguni languages (zul, xho, nbl, ssw) and the Sotho languages (nso, sot, tsn) are similar to each other."}
{"sample": "They compared layer-wise trained models with Xavier initialization models, and 2-layers distilled models with 2-layers regular-trained models."}
{"sample": "29,794 articles"}
{"sample": "A group of 50 native people who were well-versed in both English and Tamil languages acted as annotators for the evaluation."}
{"sample": "Yes"}
{"sample": "Models are evaluated by the retention rate of tokens and the fraction of sentences that exactly match the target sentence."}
{"sample": "Precision, Recall, F-measure, overall accuracy"}
{"sample": "The source domain is the existing domain with sufficient labeled data, and the target domain is the new domain with very few or no labeled data."}
{"sample": "LSTMs, RAN, QRNN, NAS"}
{"sample": "Word/character embedding, RNN, CNN, QRNN, Transformer, Highway network, Encoder Decoder architecture, attention layers, regularization layers, and loss functions."}
{"sample": "multilingual pronunciation corpus collected by deri2016grapheme from Wiktionary"}
{"sample": "unanswerable"}
{"sample": "English, Spanish, Finnish."}
{"sample": "unanswerable"}
{"sample": "Yes"}
{"sample": "Yes"}
{"sample": "By generating maps for word categories that reflect certain psycholinguistic or semantic properties using lexical resources like Roget or Linguistic Inquiry and Word Count."}
{"sample": "claim, premise, backing, rebuttal, and refutation"}
{"sample": "unanswerable"}
{"sample": "1,873 Twitter conversation threads"}
{"sample": "English, Mandarin Chinese, Yue Chinese, Spanish, Russian, French, Polish, Estonian, Finnish, Hebrew, Kiswahili, Welsh."}
{"sample": "Wikipedia 'Conversations Gone Awry' dataset and Reddit CMV dataset."}
{"sample": "unanswerable"}
{"sample": "The quality of the data is empirically evaluated through various sanity checks, including computing sentence-level BLEU scores, manual inspection of translations, perplexity measurements using a language model, character ratio computations, and similarity scores based on LASER cross-lingual sentence embeddings."}
{"sample": "The audio and text sequences are encoded using dual RNNs and then combined using a feed-forward neural model to predict the emotion class."}
{"sample": "2.11 BLEU, 1.7 FKGL, and 1.07 SARI."}
{"sample": "700 examples"}
{"sample": "A tweet went viral if it was retweeted more than 1000 times."}
{"sample": "unanswerable"}
{"sample": "crowdsourcing"}
{"sample": "Logistic Regression and deep learning model adapted from Bowman et al."}
{"sample": "The benchmark dataset is the Social Honeypot dataset, and its quality is not explicitly stated as high or low in the context provided."}
{"sample": "LSTM decoder"}
{"sample": "unanswerable"}
{"sample": "3rd position in FLC task."}
{"sample": "The baseline was the M2M Transformer NMT model (b3)."}
{"sample": "0.7033"}
{"sample": "Second-order co-occurrence vectors and word embeddings."}
{"sample": "Using a bilingual dictionary."}
{"sample": "Yes"}
{"sample": "Experts with legal training."}
{"sample": "Painting embedding: 3 parallel CNNs (object CNN, sentiment CNN, and scene CNN) combined with a skip-thought model; Language style transfer: sequence-to-sequence models with attention and pointer networks."}
{"sample": "The transformer layer works better."}
{"sample": "Yes"}
{"sample": "personal attack, racism, and sexism"}
{"sample": "By splitting the sentence into three disjoint regions (left context, middle context, right context) and focusing on the extended middle context by using two combinations: (1) left context, left entity, and middle context; (2) middle context, right entity, and right context."}
{"sample": "Four types (PER, LOC, ORG, and MISC)"}
{"sample": "unanswerable"}
{"sample": "Women represent 33.16% of the speakers and account for only 22.57% of the total speech time."}
{"sample": "English-German dataset"}
{"sample": "BIBREF2, BIBREF13, BIBREF4, BIBREF15, BIBREF10, BIBREF17, BIBREF18, BIBREF20, BIBREF23, BIBREF33, BIBREF34, BIBREF35, BIBREF36, BIBREF37."}
{"sample": "Logistic Regression (LR) and Multilayer Perceptron (MLP)"}
{"sample": "BIBREF23, BIBREF17, BIBREF18, BIBREF19, BIBREF24, BIBREF25, BIBREF26, TwitterNLP, CogComp-NLP, Stanford NLP NER, spaCy NER."}
{"sample": "SQuAD dataset"}
{"sample": "Modelling urban regions, identifying points-of-interest and itineraries, predicting environmental phenomena using bag-of-words representations derived from Flickr tags, and using vector space embeddings for modelling geographic locations."}
{"sample": "Yes"}
{"sample": "CSAT dataset, 20 newsgroups, and Fisher Phase 1 corpus."}
{"sample": "IMDb movie review dataset"}
{"sample": "Yes"}
{"sample": "No."}
{"sample": "The invertibility condition requires the neural projector to be invertible and its inverse to exist."}
{"sample": "unanswerable"}
{"sample": "WikiSmall: 89,042 sentence pairs; WikiLarge: 296,402 sentence pairs."}
{"sample": "Vanilla ST baseline, encoder pre-training, decoder pre-training, encoder-decoder pre-training, one-to-many multi-task, many-to-one multi-task, many-to-many multi-task, many-to-many+pre-training, Triangle+pre-train."}
{"sample": "unanswerable"}
{"sample": "linear SVM, bidirectional Long Short-Term-Memory (BiLSTM) model, Convolutional Neural Network (CNN)"}
{"sample": "unanswerable"}
{"sample": "200-dimensional GloVe embeddings and Edinburgh embeddings."}
{"sample": "Our personalized generative models can generate plausible, personalized, and coherent recipes preferred by human evaluators for consumption."}
{"sample": "harmonic mean of irony reward and sentiment reward"}
{"sample": "The generated English poem may not work well with Shakespeare style transfer if the style transfer dataset does not have similar words in the training set of sentences."}
{"sample": "The Affective Text dataset, the Fairy Tales dataset, and the ISEAR dataset."}
{"sample": "The distribution results showed statistically significant differences in the distribution of followers, no significant difference in retweets and favourites, a larger number of hashtags in viral fake news (though not statistically significant), a higher chance of fake news coming from unverified accounts, a statistically significant difference in the distribution of friends, a larger ratio of friends/followers for accounts spreading fake news, less frequent use of mentions in tweets containing fake news, no statistically significant difference in the presence of media elements, and more URLs in viral tweets containing fake news."}
{"sample": "The dataset of hashtags is sourced from the Stanford Sentiment Analysis Dataset."}
{"sample": "unanswerable"}
{"sample": "The context of the corresponding text."}
{"sample": "B1 and B2"}
{"sample": "unanswerable"}
{"sample": "unanswerable"}
{"sample": "SemEval-2016 \u201cSentiment Analysis in Twitter\u201d task dataset."}
{"sample": "small BERT"}
{"sample": "Yes"}
{"sample": "Yes"}
{"sample": "Competitive or even state-of-the-art results for some of the emotion labels on existing, standard evaluation datasets."}
{"sample": "{B-PUN, I-PUN, O}"}
{"sample": "No"}
{"sample": "Robustness of a model is defined as its ability to leverage prior knowledge without being misled by bias in the knowledge."}
{"sample": "InferSent, Universal Sentence Encoder, average GloVe embeddings, and BiLSTM architecture."}
{"sample": "English datasets: CoNLL2003 (+0.29), OntoNotes5.0 (+0.96); Chinese datasets: MSRA (+0.97), OntoNotes4.0 (+2.36)."}
{"sample": "Task 1: Quora Duplicate Question Pair Detection and Task 2: Ranking questions in Bing's People Also Ask."}
{"sample": "syntactic tree-based models, latent tree models, and non-tree models"}
{"sample": "Relation detection."}
{"sample": "Nearest-Neighbor model (NN) and Encoder-Decoder baseline with ingredient attention (Enc-Dec)."}
{"sample": "Browser-based annotation tool, manual categorization, part-of-speech tagging, leveraging Flickr30K Entities dataset with coreference annotations and clustering."}
{"sample": "French, Spanish, Italian, Portuguese, Arabic, Hebrew, German, and English."}
{"sample": "CAS-LSTM, plain stacked LSTMs, models with different INLINEFORM0, models without INLINEFORM1, and models that integrate lower contexts via peephole connections."}
{"sample": "Yes"}
{"sample": "ILP-based summarization, Sumy package algorithms"}
{"sample": "BIBREF7"}
{"sample": "unanswerable"}
{"sample": "DTA18 and DTA19"}
{"sample": "Kannada, Hindi, Telugu, Malayalam, Bengali, and English."}
{"sample": "Unanswerable"}
{"sample": "ALOHA achieves a significant improvement on the target character language style retrieval task compared to the baseline open-domain chatbot models."}
{"sample": "unanswerable"}
{"sample": "The authors present evidence of biases in data annotation and collection by showing that many errors are due to biases from data collection and rules of annotation, and by manual inspection of mislabeled items, where tweets with specific language or geographic restriction are oversampled, resulting in high rates of misclassification."}
{"sample": "Yes."}
{"sample": "unanswerable"}
{"sample": "+0.58 for MRPC and +0.73 for QQP."}
{"sample": "BIBREF0"}
{"sample": "unanswerable"}
{"sample": "Pointer-Gen, Pointer-Gen+Pos, Pointer-Gen+Same-FT, Pointer-Gen+Pos-FT, Pointer-Gen+RL-ROUGE, Pointer-Gen+RL-SEN, Pointer-Gen+ARL-SEN."}
{"sample": "Na\u00efve Bayes, Logistic Regression, Support Vector Machine, Random Forests, Gradient Boosted Trees, Convolutional Neural Networks, Recurrent Neural Networks."}
{"sample": "bi-directional language model and uni-directional model"}
{"sample": "Weights are dynamically adjusted in proportion to $(1-p)$, and this weight dynamically changes as training proceeds."}
{"sample": "KG-A2C-chained and KG-A2C-Explore both pass the bottleneck of a score of 40, whereas A2C-Explore gets to the bottleneck but cannot surpass it. KG-A2C-chained is significantly more sample efficient and converges faster than KG-A2C-Explore."}
{"sample": "Bayesian models for each language and crosslingual latent variables to incorporate soft role agreement between aligned constituents."}
{"sample": "Annotations for noises and disfluencies including mispronunciations."}
{"sample": "unanswerable"}
{"sample": "Bulgarian, Croatian, Czech, Danish, English, French, German, Indonesian, Italian, Norwegian, Persian, Polish, Portuguese, Slovenian, Spanish, and Swedish."}
{"sample": "NCEL consistently outperforms various baselines with a favorable generalization ability."}
{"sample": "Yes"}
{"sample": "AdaDelta BIBREF15"}
{"sample": "2010 i2b2/VA"}
{"sample": "Masking words in the decoder is helpful because it allows the refine decoder to generate more fluent and natural sequences by using the ability of the contextual language model to predict words given the complete context consistent with their pre-training processes."}
{"sample": "unanswerable"}
{"sample": "TF-IDF features"}
{"sample": "Each tweet is annotated as no evidence of depression or evidence of depression, and if evidence of depression is present, it is further annotated with one or more depressive symptoms."}
{"sample": "unanswerable"}
{"sample": "The training data was translated using the machine translation platform Apertium."}
{"sample": "multinomial Naive Bayes classifier"}
{"sample": "The baseline for the SLC task was a logistic regression classifier with the length of the sentence as a feature, and for the FLC task, it was a random baseline that generates spans and selects one of the 18 techniques randomly."}
{"sample": "CRF-based model, prior works that did not employ joint learning, and a \"pipeline\" method."}
{"sample": "The political bias of different sources is included in the model by assigning a political bias label to different US outlets following the procedure described in BIBREF2."}
{"sample": "The ancient Chinese dataset comes from 1.7K bilingual ancient-modern Chinese articles from the internet, including ancient Chinese history records in several dynasties (about 1000BC-200BC) and articles written by celebrities of that era."}
{"sample": "English"}
{"sample": "unanswerable"}
{"sample": "Three convolutional layers."}
{"sample": "European network of nature protected sites Natura 2000, CORINE land cover classes, SoilGrids, and the ScenicOrNot dataset."}
{"sample": "NUBes-PHI and the MEDDOCAN corpus."}
{"sample": "Unigrams, pragmatic features, stylistic patterns, and patterns related to situational disparity."}
{"sample": "Coverage(C), Avg. MCC, and avg. +ve F1 score."}
{"sample": "Yes"}
{"sample": "Galatasaray (Target-1) and Fenerbah\u00e7e (Target-2)"}
{"sample": "Automatic evaluations and human evaluations on the transformation from non-ironic sentences to ironic sentences, and additional experiments on the transformation from ironic sentences to non-ironic sentences."}
{"sample": "Gaussian-masked directional multi-head attention works by applying a Gaussian weight matrix that emphasizes the localness relationship between characters based on their distances, adjusting the attention weights to favor adjacent characters, and using a triangular matrix mask for forward and backward encoders to focus on different weights."}
{"sample": "Facebook status update messages."}
{"sample": "The features extracted from the network's baseline CNN that directly aims to classify a sentence as sarcastic vs non-sarcastic."}
{"sample": "The number of clusters (k) and the type of word vector models (skipgram, cbow, GloVe)."}
{"sample": "unanswerable"}
{"sample": "The corpus consists of 53 documents."}
{"sample": "Unanswerable"}
{"sample": "text categorization and sentiment classification"}
{"sample": "CNN, term frequency models, and rule-based pattern matching."}
{"sample": "The training sets for these versions of ELMo are much larger, with the Latvian corpus having about 280 million tokens compared to the ELMoForManyLangs' 20 million tokens."}
{"sample": "6946 sentences"}
{"sample": "MLP, Eusboost, MWMOTE"}
{"sample": "Yes"}
{"sample": "No"}
{"sample": "0.6103"}
{"sample": "Wall Street Journal (WSJ) portion of the Penn Treebank"}
{"sample": "unanswerable"}
{"sample": "SimpleQuestions and WebQSP"}
